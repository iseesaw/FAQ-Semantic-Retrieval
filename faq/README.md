# FAQ-Semantic-Retrieval

![](https://img.shields.io/badge/python-â‰¥3.6-blue?style=for-the-badge&logo=python&link=https://pytorch.org/)  ![](https://img.shields.io/badge/pytorch-1.6.0-yello?style=for-the-badge&logo=pytorch&link=https://pytorch.org/)  ![](https://img.shields.io/badge/transformers-â‰¥3.0.2-orange?style=for-the-badge&link=https://huggingface.co/landing/assets/transformers-docs/huggingface_logo.svg) 

ä¸€ç§ FAQ å‘é‡è¯­ä¹‰æ£€ç´¢è§£å†³æ–¹æ¡ˆ

- [x] åŸºäº [**Sklearn Kmeans**](https://scikit-learn.org/stable/) èšç±»çš„**è´Ÿé‡‡æ ·**

- [x] åŸºäº [**Transformers**](https://huggingface.co/transformers/) çš„ BertForSiameseNetworkï¼ˆBert**åŒå¡”æ¨¡å‹**ï¼‰**å¾®è°ƒè®­ç»ƒ**

- [x] åŸºäº [**TextBrewer**](https://github.com/airaria/TextBrewer) çš„**æ¨¡å‹è’¸é¦**

- [x] åŸºäº [**FastAPI**](https://fastapi.tiangolo.com/zh/) å’Œ [**Locust**](https://locust.io/) çš„ **WebAPI æœåŠ¡**ä»¥åŠ**å‹åŠ›æµ‹è¯•**



## é¡¹ç›®ä»‹ç»

FAQ çš„å¤„ç†æµç¨‹ä¸€èˆ¬ä¸ºï¼š

- **é—®é¢˜ç†è§£**ï¼Œå¯¹ç”¨æˆ· query è¿›è¡Œæ”¹å†™ä»¥åŠå‘é‡è¡¨ç¤º
- **å¬å›æ¨¡å—**ï¼Œåœ¨é—®é¢˜é›†ä¸Šè¿›è¡Œå€™é€‰é—®é¢˜å¬å›ï¼Œè·å¾— topkï¼ˆåŸºäºå…³é”®å­—çš„å€’æ’ç´¢å¼• vs åŸºäºå‘é‡çš„è¯­ä¹‰å¬å›ï¼‰
- **æ’åºæ¨¡å—**ï¼Œå¯¹ topk è¿›è¡Œç²¾æ’åº

æœ¬é¡¹ç›®ç€çœ¼äº **å¬å›æ¨¡å—** çš„ **å‘é‡æ£€ç´¢** çš„å®ç°ï¼Œé€‚ç”¨äº **å°è§„æ¨¡ FAQ é—®é¢˜é›†**ï¼ˆå€™é€‰é—®é¢˜é›†<10ä¸‡ï¼‰çš„ç³»ç»Ÿå¿«é€Ÿæ­å»º



### FAQ è¯­ä¹‰æ£€ç´¢

ä¼ ç»Ÿå¬å›æ¨¡å—**åŸºäºå…³é”®å­—æ£€ç´¢**

- è®¡ç®—å…³é”®å­—åœ¨é—®é¢˜é›†ä¸­çš„ [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) ä»¥åŠ[ BM25](https://en.wikipedia.org/wiki/Okapi_BM25) å¾—åˆ†ï¼Œå¹¶å»ºç«‹**å€’æ’ç´¢å¼•è¡¨**
- ç¬¬ä¸‰æ–¹åº“ [ElasticSearch](https://whoosh.readthedocs.io/en/latest/index.html)ï¼Œ[Lucene](https://lucene.apache.org/pylucene/)ï¼Œ[Whoosh](https://whoosh.readthedocs.io/en/latest/index.html)



éšç€è¯­ä¹‰è¡¨ç¤ºæ¨¡å‹çš„å¢å¼ºã€é¢„è®­ç»ƒæ¨¡å‹çš„å‘å±•ï¼ŒåŸºäº BERT å‘é‡çš„**è¯­ä¹‰æ£€ç´¢**å¾—åˆ°å¹¿æ³›åº”ç”¨

- å¯¹å€™é€‰é—®é¢˜é›†åˆè¿›è¡Œå‘é‡ç¼–ç ï¼Œå¾—åˆ° **corpus å‘é‡çŸ©é˜µ**
- å½“ç”¨æˆ·è¾“å…¥ query æ—¶ï¼ŒåŒæ ·è¿›è¡Œç¼–ç å¾—åˆ° **query å‘é‡è¡¨ç¤º**
- ç„¶åè¿›è¡Œè¯­ä¹‰æ£€ç´¢ï¼ˆçŸ©é˜µæ“ä½œï¼ŒKNNï¼ŒFAISSï¼‰



æœ¬é¡¹ç›®é’ˆå¯¹å°è§„æ¨¡ FAQ é—®é¢˜é›†ç›´æ¥è®¡ç®— query å’Œ corpus å‘é‡çŸ©é˜µçš„**ä½™å¼¦ç›¸ä¼¼åº¦**ï¼Œä»è€Œè·å¾— topk å€™é€‰é—®é¢˜
$$
score = \frac{V_{query} \cdot V_{corpus}}{||V_{query}|| \cdot ||V_{corpus}||}
$$
**å¥å‘é‡è·å–è§£å†³æ–¹æ¡ˆ**

| Python Lib                                                   | Framework  | Desc                                                    | Example                                                      |
| ------------------------------------------------------------ | ---------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| [bert-as-serivce](https://github.com/hanxiao/bert-as-service) | TensorFlow | é«˜å¹¶å‘æœåŠ¡è°ƒç”¨ï¼Œæ”¯æŒ fine-tuneï¼Œè¾ƒéš¾æ‹“å±•å…¶ä»–æ¨¡å‹        | [getting-started](https://github.com/hanxiao/bert-as-service#getting-started) |
| [Sentence-Transformers](https://www.sbert.net/index.html)    | PyTorch    | æ¥å£ç®€å•æ˜“ç”¨ï¼Œæ”¯æŒå„ç§æ¨¡å‹è°ƒç”¨ï¼Œæ”¯æŒ fine-turnï¼ˆå•GPUï¼‰ | [using-Sentence-Transformers-model](https://www.sbert.net/docs/quickstart.html#quickstart)<br />[using-Transformers-model](https://github.com/UKPLab/sentence-transformers/issues/184#issuecomment-607069944) |
| ğŸ¤— [Transformers](https://github.com/huggingface/transformers/) | PyTorch    | è‡ªå®šä¹‰ç¨‹åº¦é«˜ï¼Œæ”¯æŒå„ç§æ¨¡å‹è°ƒç”¨ï¼Œæ”¯æŒ fine-turnï¼ˆå¤šGPUï¼‰ | [sentence-embeddings-with-Transformers](https://www.sbert.net/docs/usage/computing_sentence_embeddings.html#sentence-embeddings-with-transformers) |

> - **Sentence-Transformers** è¿›è¡Œå°è§„æ¨¡æ•°æ®çš„å• GPU fine-tune å®éªŒï¼ˆå°šä¸æ”¯æŒå¤š GPU è®­ç»ƒï¼Œ[Multi-GPU-training #311](https://github.com/UKPLab/sentence-transformers/issues/311#issuecomment-659455875) ï¼›å®ç°äº†å¤šç§ [Ranking loss](https://www.sbert.net/docs/package_reference/losses.html) å¯ä¾›å‚è€ƒï¼‰
> - **Transformers** è¿›è¡Œå¤§è§„æ¨¡æ•°æ®çš„å¤š GPU fine-tune è®­ç»ƒï¼ˆæ¨èè‡ªå®šä¹‰æ¨¡å‹ä½¿ç”¨ [Trainer](https://huggingface.co/transformers/training.html#trainer) è¿›è¡Œè®­ç»ƒï¼‰
> - å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­ **Sentence-Transformers** å’Œ **Transformers** æ¨¡å‹åŸºæœ¬äº’é€šäº’ç”¨ï¼Œå‰è€…å¤šäº† **Pooling å±‚ï¼ˆMean/Max/CLS Poolingï¼‰** ï¼Œå¯å‚è€ƒ **Example**
> - :fire: **å®é™…ä¸Šçº¿æ¨èç›´æ¥ä½¿ç”¨ Transformers å°è£…ï¼ŒSentence-Transformers åœ¨ CPU ä¸Šè¿è¡Œå­˜åœ¨é—®é¢˜ï¼ï¼ï¼** ï¼ˆå¹¶ä¸”å¯ä»¥å°‘å®‰è£…ä¸€ä¸ªåŒ…ã€‚ã€‚ï¼‰



### BERT å¾®è°ƒä¸è’¸é¦

åœ¨å¥å‘é‡è·å–ä¸­å¯ä»¥ç›´æ¥ä½¿ç”¨ [bert-base-chinese](https://huggingface.co/bert-base-chinese) ä½œä¸ºç¼–ç å™¨ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸæ•°æ®ä¸Šå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ fine-tune æ¥è·å–æ›´å¥½çš„æ•ˆæœ

fine-tune è¿‡ç¨‹ä¸»è¦è¿›è¡Œ**æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—**ä»»åŠ¡ï¼Œäº¦**å¥å¯¹åˆ†ç±»ä»»åŠ¡**ï¼›æ­¤å¤„æ˜¯ä¸ºè·å¾—æ›´å¥½çš„å¥å‘é‡ï¼Œå› æ­¤ä½¿ç”¨**åŒå¡”æ¨¡å‹ï¼ˆ[SiameseNetwork](https://en.wikipedia.org/wiki/Siamese_neural_network) ï¼Œå­ªç”Ÿç½‘ç»œï¼‰**å¾®è°ƒï¼Œè€Œéå¸¸ç”¨çš„åŸºäºè¡¨ç¤ºçš„æ¨¡å‹ [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) 



#### BertForSiameseNetwork

**BertForSiameseNetwork** ä¸»è¦æ­¥éª¤å¦‚ä¸‹

- **Encoding**ï¼Œä½¿ç”¨ï¼ˆåŒä¸€ä¸ªï¼‰ **BERT** åˆ†åˆ«å¯¹ query å’Œ candidate è¿›è¡Œç¼–ç 
- **Pooling**ï¼Œå¯¹æœ€åä¸€å±‚è¿›è¡Œ**æ± åŒ–æ“ä½œ**è·å¾—å¥å­è¡¨ç¤ºï¼ˆMean/Max/CLS Poolingï¼‰
- **Computing**ï¼Œè®¡ç®—ä¸¤ä¸ªå‘é‡çš„**ä½™å¼¦ç›¸ä¼¼åº¦**ï¼ˆæˆ–å…¶ä»–åº¦é‡å‡½æ•°ï¼‰ï¼Œè®¡ç®— loss è¿›è¡Œåå‘ä¼ æ’­

![](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/SBERT_Siamese_Network.png)

#### æŸå¤±å‡½æ•°

æ¨¡å‹è®­ç»ƒä½¿ç”¨çš„æŸå¤±å‡½æ•°ä¸º **Ranking loss**ï¼Œä¸åŒäºCrossEntropy å’Œ MSE è¿›è¡Œåˆ†ç±»å’Œå›å½’ä»»åŠ¡ï¼Œ**Ranking loss** ç›®çš„æ˜¯é¢„æµ‹è¾“å…¥æ ·æœ¬å¯¹ï¼ˆå³ä¸Šè¿°åŒå¡”æ¨¡å‹ä¸­ $u$ å’Œ $v$ ä¹‹é—´ï¼‰ä¹‹é—´çš„ç›¸å¯¹è·ç¦»ï¼ˆ**åº¦é‡å­¦ä¹ ä»»åŠ¡**ï¼‰

- **Contrastive Loss**

  > æ¥è‡ª LeCun [Dimensionality Reduction by Learning an Invariant Mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)
  >
  > [sentence-transformers æºç å®ç°](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/ContrastiveLoss.py)

  - å…¬å¼å½¢å¼å¦‚ä¸‹ï¼Œå…¶ä¸­ $u, v$ ä¸º BERT ç¼–ç çš„å‘é‡è¡¨ç¤ºï¼Œ$y$ ä¸ºå¯¹åº”çš„æ ‡ç­¾ï¼ˆ1 è¡¨ç¤ºæ­£æ ·æœ¬ï¼Œ0 è¡¨ç¤ºè´Ÿæ ·æœ¬ï¼‰ï¼Œ $\tau$ ä¸ºè¶…å‚æ•°
    $$
    L(u_i, v_i, y_i) =  y_i ||u_i, v_i|| + (1 - y_i) \max(0, \tau - ||u_i, v_i||
    $$

  - å…¬å¼æ„ä¹‰ä¸ºï¼šå¯¹äº**æ­£æ ·æœ¬**ï¼Œè¾“å‡ºç‰¹å¾å‘é‡ä¹‹é—´è·ç¦»è¦**å°½é‡å°**ï¼›è€Œå¯¹äº**è´Ÿæ ·æœ¬**ï¼Œè¾“å‡ºç‰¹å¾å‘é‡é—´è·ç¦»è¦**å°½é‡å¤§**ï¼›ä½†æ˜¯è‹¥**è´Ÿæ ·æœ¬é—´è·å¤ªå¤§**ï¼ˆå³å®¹æ˜“åŒºåˆ†çš„**ç®€å•è´Ÿæ ·æœ¬**ï¼Œé—´è·å¤§äº $\tau$ï¼‰**åˆ™ä¸å¤„ç†**ï¼Œè®©æ¨¡å‹å…³æ³¨æ›´åŠ **éš¾ä»¥åŒºåˆ†**çš„æ ·æœ¬



- **OnlineContrastive Loss**

  - å±äº **online negative sampling** ï¼Œä¸ **Contrastive Loss** ç±»ä¼¼

  - å‚è€ƒ [sentence-transformers æºç å®ç°](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/OnlineContrastiveLoss.py) ï¼Œåœ¨æ¯ä¸ª batch å†…ï¼Œé€‰æ‹©æœ€éš¾ä»¥åŒºåˆ†çš„æ­£ä¾‹æ ·æœ¬å’Œè´Ÿä¾‹æ ·æœ¬è¿›è¡Œ loss è®¡ç®—ï¼ˆå®¹æ˜“è¯†åˆ«çš„æ­£ä¾‹å’Œè´Ÿä¾‹æ ·æœ¬åˆ™å¿½ç•¥ï¼‰

  - å…¬å¼å½¢å¼å¦‚ä¸‹ï¼Œå¦‚æœæ­£æ ·æœ¬è·ç¦»å°äº $\tau_1$ åˆ™ä¸å¤„ç†ï¼Œå¦‚æœè´Ÿæ ·æœ¬è·ç¦»å¤§äº $\tau_0$ åˆ™ä¸å¤„ç†ï¼Œå®ç°è¿‡ç¨‹ä¸­ $\tau_0, \tau_1$ å¯ä»¥åˆ†åˆ«å–è´Ÿ/æ­£æ ·æœ¬çš„å¹³å‡è·ç¦»å€¼
    $$
    L(u_i, v_i, y_i) 
    \begin{cases}
    \max (0, ||u_i, v_i|| - \tau_1) ,\ if \ y_i=1 & \\
    \max (0, \tau_0 - ||u_i, v_i||),\ if \ y_i =0
    \end{cases}
    $$

æœ¬é¡¹ç›®ä½¿ç”¨ **OnlineContrastive Loss** ï¼Œæ›´å¤š Ranking loss ä¿¡æ¯å¯å‚è€ƒåšå®¢ [Understanding Ranking Loss, Contrastive Loss, Margin Loss, Triplet Loss, Hinge Loss and all those confusing names](https://gombru.github.io/2019/04/03/ranking_loss/) ï¼Œä»¥åŠ SentenceTransformers ä¸­çš„ [Loss API](https://www.sbert.net/docs/package_reference/losses.html) ä»¥åŠ PyTorch ä¸­çš„ [margin_ranking_loss](https://pytorch.org/docs/master/nn.functional.html#margin-ranking-loss)



#### æ•°æ®é›†

- **æ–‡æœ¬ç›¸ä¼¼åº¦æ•°æ®é›†**

  - ç›¸å…³è®ºæ–‡æ¯”èµ›å‘å¸ƒçš„æ•°æ®é›†å¯è§ [æ–‡æœ¬ç›¸ä¼¼åº¦æ•°æ®é›†](https://github.com/IceFlameWorm/NLP_Datasets) ï¼Œå¤§éƒ¨åˆ†ä¸ºé‡‘èç­‰ç‰¹å®šé¢†åŸŸæ–‡æœ¬ï¼Œå…¶ä¸­ [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) æä¾›åŸºäºç™¾åº¦çŸ¥é“çš„çº¦ 20w+ å¼€æ”¾åŸŸé—®é¢˜æ•°æ®é›†ï¼Œå¯ä¾›æ¨¡å‹æµ‹è¯•

    | data       | total  | positive | negative |
    | ---------- | ------ | -------- | -------- |
    | training   | 238766 | 138574   | 100192   |
    | validation | 8802   | 4402     | 4400     |
    | test       | 12500  | 6250     | 6250     |

  - é™¤æ­¤ä»¥å¤–ï¼Œç™¾åº¦[åƒè¨€é¡¹ç›®](https://www.luge.ai/)å‘å¸ƒäº†[æ–‡æœ¬ç›¸ä¼¼åº¦è¯„æµ‹](https://aistudio.baidu.com/aistudio/competition/detail/45)ï¼ŒåŒ…å« LCQMC/BQ Corpus/PAWS-X ç­‰æ•°æ®é›†ï¼Œå¯ä¾›å‚è€ƒ

- **FAQæ•°æ®é›†**

  - å†…éƒ¨ç»™å®šçš„ FAQ æ•°æ®é›†å½¢å¼å¦‚ä¸‹ï¼ŒåŒ…æ‹¬å„ç§â€ä¸»é¢˜/é—®é¢˜â€œï¼Œæ¯ç§â€œä¸»é¢˜/é—®é¢˜â€å¯ä»¥æœ‰å¤šç§ä¸åŒè¡¨è¾¾å½¢å¼çš„é—®é¢˜ `post`ï¼ŒåŒæ—¶å¯¹åº”å¤šç§å½¢å¼çš„å›å¤ `resp` 

  - æ£€ç´¢æ—¶åªéœ€è¦å°† query ä¸æ‰€æœ‰ post è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—ï¼Œä»è€Œå¬å›æœ€ç›¸ä¼¼çš„ post ï¼Œç„¶åè·å–å¯¹åº”çš„ â€œä¸»é¢˜/é—®é¢˜â€ çš„æ‰€æœ‰å›å¤ `resp` ï¼Œæœ€åéšæœºè¿”å›ä¸€ä¸ªå›å¤å³å¯

    ```python
    {
       "æ™šå®‰": {
           "post": [
                "10ç‚¹äº†ï¼Œæˆ‘è¦ç¡è§‰äº†",
                "å”‰ï¼Œè¯¥ä¼‘æ¯äº†",
             		...
            ],
           "resp": [
                "ç¥ä½ åšä¸ªå¥½æ¢¦",
                "ç¥ä½ æœ‰ä¸ªå¥½æ¢¦ï¼Œæ™šå®‰ï¼",
                ...
            ]
         },
      	"æ„Ÿè°¢": {
          	"post": [
            		"å¤šè°¢äº†",
           		 "éå¸¸æ„Ÿè°¢",
              ...
          	],
          	"resp": [
            		"åŠ©äººä¸ºä¹ä¸ºå¿«ä¹ä¹‹æœ¬",
            		"åˆ«å®¢æ°”",
              	...
          	]
        },
      	...
    }
    ```

  - å†…éƒ¨FAQæ•°æ®åŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬

    - chitchat-faq-smallï¼Œä¸»è¦æ˜¯å°è§„æ¨¡é—²èŠFAQï¼Œ1500ä¸»é¢˜é—®é¢˜ï¼ˆtopicï¼‰ã€2ä¸‡å¤šä¸åŒå½¢å¼é—®é¢˜ï¼ˆpostï¼‰
    - entity-faq-largeï¼Œä¸»è¦æ˜¯å¤§è§„æ¨¡å®ä½“FAQï¼ˆæ¶‰åŠä¸šåŠ¡é—®é¢˜ï¼‰ï¼Œå¤§çº¦3-5åƒä¸»é¢˜é—®é¢˜ï¼ˆtopicï¼‰ã€12ä¸‡ä¸åŒå½¢å¼é—®é¢˜ï¼ˆpostï¼‰



#### è´Ÿé‡‡æ ·

å¯¹äºæ¯ä¸ª queryï¼Œéœ€è¦è·å¾—ä¸å…¶ç›¸ä¼¼çš„ **positve candidate** ä»¥åŠä¸ç›¸ä¼¼çš„ **negtive candidate**ï¼Œä»è€Œæ„æˆæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ä½œä¸ºæ¨¡å‹è¾“å…¥ï¼Œå³ **(query, candidate)**

> âš ï¸ æ­¤å¤„ä¸º **offline negtive sampling**ï¼Œå³åœ¨è®­ç»ƒå‰é‡‡æ ·æ„é€ è´Ÿæ ·æœ¬ï¼ŒåŒºåˆ«äº **online negtive sampling**ï¼Œåè€…åœ¨è®­ç»ƒä¸­çš„æ¯ä¸ª batch å†…è¿›è¡ŒåŠ¨æ€çš„è´Ÿé‡‡æ ·ï¼ˆå¯ä»¥é€šè¿‡ç›¸å…³æŸå¤±å‡½æ•°å®ç°ï¼Œå¦‚ **OnlineContrastive Loss**ï¼‰
>
> ä¸¤ç§æ–¹æ³•å¯ä»¥æ ¹æ®ä»»åŠ¡ç‰¹æ€§è¿›è¡Œé€‰æ‹©ï¼Œ**online negtive sampling** å¯¹äºæ•°æ®é›†æœ‰ä¸€å®šçš„è¦æ±‚ï¼Œéœ€è¦ç¡®ä¿æ¯ä¸ª batch å†…çš„ query æ˜¯ä¸ç›¸ä¼¼çš„ï¼Œä½†æ˜¯æ•ˆç‡æ›´é«˜

å¯¹äº **offline negtive sampling** ä¸»è¦ä½¿ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹å¼é‡‡æ ·ï¼š

- **å…¨å±€è´Ÿé‡‡æ ·**
  - åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œæ­£æ€åˆ†å¸ƒé‡‡æ ·ï¼Œå¾ˆéš¾äº§ç”Ÿé«˜éš¾åº¦çš„è´Ÿæ ·æœ¬
- **å±€éƒ¨è´Ÿé‡‡æ ·**
  - é¦–å…ˆä½¿ç”¨å°‘é‡äººå·¥æ ‡æ³¨æ•°æ®é¢„è®­ç»ƒçš„ **BERT æ¨¡å‹**å¯¹å€™é€‰é—®é¢˜é›†åˆè¿›è¡Œ**ç¼–ç **
  - ç„¶åä½¿ç”¨**æ— ç›‘ç£èšç±»** ï¼Œå¦‚ [Kmeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) 
  - æœ€ååœ¨æ¯ä¸ª query æ‰€åœ¨èšç±»ç°‡ä¸­è¿›è¡Œé‡‡æ ·



å®éªŒä¸­å¯¹å·²æœ‰ FAQ æ•°æ®é›†ä¸­æ‰€æœ‰ä¸»é¢˜çš„ post è¿›è¡Œ **9:1** åˆ’åˆ†å¾—åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œè´Ÿé‡‡æ ·ç»“æœå¯¹æ¯”

| dataset                       | topics | posts | positive(sampling) | negative(sampling) | total(sampling) |
| ----------------------------- | ------ | ----- | ------------------ | ------------------ | --------------- |
| chitchat-faq-small<br />train | 1468   | 18267 | 5w+                | 5w+                | 10w+            |
| chitchat-faq-small<br />test  | 768    | 2030  | 2984               | 7148               | 10132           |
| chitchat-faq-small            | 1500   | 20297 | -                  | -                  | -               |
| entity-faq-large              | -      | 12w+  | 50w+               | 50w+               | 100w+           |



#### æ¨¡å‹è’¸é¦

ä½¿ç”¨åŸºäº Transformers çš„æ¨¡å‹è’¸é¦å·¥å…· [TextBrewer](https://github.com/airaria/TextBrewer) ï¼Œå‚è€ƒ [å®˜æ–¹ å…¥é—¨ç¤ºä¾‹](https://github.com/airaria/TextBrewer/tree/master/examples/random_tokens_example) å’Œ[cmrc2018ç¤ºä¾‹](https://github.com/airaria/TextBrewer/tree/master/examples/cmrc2018_example)



### FAQ WebæœåŠ¡

#### Web API

- Web æ¡†æ¶é€‰æ‹©
  - [Flask](https://flask.palletsprojects.com/) + Gunicorn + gevent + nginx ï¼Œè¿›ç¨‹ç®¡ç†ï¼ˆå´©æºƒè‡ªåŠ¨é‡å¯ï¼‰ï¼ˆuwsgi åŒç†ï¼Œgunicorn æ›´ç®€å•ï¼‰
  - :fire: **[FastAPI](https://fastapi.tiangolo.com/)** + uvicornï¼ˆå´©æºƒè‡ªåŠ¨é‡å¯ï¼‰ï¼Œæœ€å¿«çš„Python Webæ¡†æ¶ï¼ˆå®æµ‹çš„ç¡®æ¯” Flask å¿«å‡ å€ï¼‰
- cache ç¼“å­˜æœºåˆ¶ï¼ˆä¿å­˜æœ€è¿‘çš„queryå¯¹åº”çš„topicï¼Œå‘½ä¸­åç›´æ¥è¿”å›ï¼‰
  - Flask ç›¸å…³
    - [flask-caching](https://github.com/sh4nks/flask-caching) ï¼ˆé»˜è®¤ç¼“å­˜500ï¼Œè¶…æ—¶300ç§’ï¼‰ï¼Œä½¿ç”¨ set/get è¿›è¡Œæ•°æ®æ“ä½œï¼›é¡¹ç›®æ¥æºäº [pallets/werkzeug](https://github.com/pallets/werkzeug) ï¼ˆwerkzeug ç‰ˆæœ¬0.4ä»¥åå¼ƒç”¨ cacheï¼‰
  - Python 3.2 ä»¥ä¸Šè‡ªå¸¦ï¼ˆFastAPI ä¸­å¯ä½¿ç”¨ï¼‰
    - :fire: [**functools.lru_cache()**](https://docs.python.org/3/library/functools.html#functools.lru_cache) ï¼ˆé»˜è®¤ç¼“å­˜128ï¼Œlruç­–ç•¥ï¼‰ï¼Œè£…é¥°å™¨ï¼Œç¼“å­˜å‡½æ•°è¾“å…¥å’Œè¾“å‡º



#### Locust å‹åŠ›æµ‹è¯•

ä½¿ç”¨ [Locust](https://locust.io/) ç¼–å†™å‹åŠ›æµ‹è¯•è„šæœ¬



## ä½¿ç”¨è¯´æ˜

ä¸»è¦ä¾èµ–å‚è€ƒ `requirements.txt`

```bash
pip install -r requirements.txt
```



### è´Ÿé‡‡æ ·

```bash
python sampling.py \
	--filename='faq/train_faq.json' \
	--model_name_or_path='./model/bert-base-chinese' \
	--is_transformers=True \
	--hyper_beta=2 \
	--num_pos=5 \
	--local_num_negs=3 \
	--global_num_negs=2 \
	--output_dir='./samples'
```

**ä¸»è¦å‚æ•°è¯´æ˜**

- `--filename` ï¼Œ**faq æ•°æ®é›†**ï¼ŒæŒ‰å‰æ–‡æ‰€è¿°ç»„ç»‡ä¸º `{topic: {post:[], resp:[]}}` æ ¼å¼
- `--model_name_or_path` ï¼Œç”¨äºå¥å‘é‡ç¼–ç çš„ Transformers **é¢„è®­ç»ƒæ¨¡å‹**ä½ç½®ï¼ˆ`bert-base-chinese` æˆ–è€…åŸºäºäººå·¥æ ‡æ³¨æ•°æ®å¾®è°ƒåçš„æ¨¡å‹ï¼‰
- `--hyper_beta` ï¼Œ**èšç±»æ•°è¶…å‚æ•°**ï¼Œèšç±»ç±»åˆ«ä¸º `n_cluster=num_topics/hyper_beta` ï¼Œå…¶ä¸­ `num_topics` ä¸ºä¸Šè¿°æ•°æ®ä¸­çš„ä¸»é¢˜æ•°ï¼Œ`hyper_beta` é»˜è®¤ä¸º 2ï¼ˆè¿‡å°å¯èƒ½æ— æ³•é‡‡æ ·åˆ°è¶³å¤Ÿå±€éƒ¨è´Ÿæ ·æœ¬ï¼‰
- `--num_pos` ï¼Œ**æ­£é‡‡æ ·ä¸ªæ•°**ï¼Œé»˜è®¤ 5ï¼ˆæ³¨æ„æ­£è´Ÿæ¯”ä¾‹åº”ä¸º 1:1ï¼‰
- `--local_num_negs` ï¼Œ**å±€éƒ¨è´Ÿé‡‡æ ·ä¸ªæ•°**ï¼Œé»˜è®¤ 3ï¼ˆè¯¥å€¼å¤ªå¤§æ—¶ï¼Œå¯èƒ½æ²¡æœ‰é‚£ä¹ˆå¤šå±€éƒ¨è´Ÿæ ·æœ¬ï¼Œéœ€è¦é€‚å½“è°ƒä½æ­£é‡‡æ ·ä¸ªæ•°ï¼Œä¿è¯æ­£è´Ÿæ¯”ä¾‹ä¸º 1:1ï¼‰
- `--global_num_negs` ï¼Œ**å…¨å±€è´Ÿé‡‡æ ·ä¸ªæ•°**ï¼Œé»˜è®¤ 2
- `--is_split` ï¼Œæ˜¯å¦è¿›è¡Œè®­ç»ƒé›†æ‹†åˆ†ï¼Œé»˜è®¤ Falseï¼ˆå»ºè®®ç›´æ¥åœ¨ faq æ•°æ®ä¸Šè¿›è¡Œæ‹†åˆ†ï¼Œç„¶åä½¿ç”¨è¯„ä¼°è¯­ä¹‰å¬å›æ•ˆæœï¼‰
- `--test_size` ï¼Œæµ‹è¯•é›†æ¯”ä¾‹ï¼Œé»˜è®¤ 0.1
- `--output_dir` ï¼Œé‡‡æ ·ç»“æœæ–‡ä»¶ä¿å­˜ä½ç½®ï¼ˆ`sentence1, sentence2, label` å½¢å¼çš„ csv æ–‡ä»¶ï¼‰



### BERT å¾®è°ƒ

- å‚è€ƒ[ Sentence-Transformers çš„ **raining_OnlineConstrativeLoss.py** ](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/quora_duplicate_questions/training_OnlineConstrativeLoss.py) ä¿®æ”¹ï¼Œé€‚åˆå• GPU å°è§„æ¨¡æ ·æœ¬è®­ç»ƒ

  - æ¨¡å‹è®­ç»ƒ
  
    ```bash
    CUDA_VISIBLE_DEVICES=0 python sentence_transformers_train.py \
      --do_train \
      --model_name_or_path='./model/bert-base-chinese' \
      --trainset_path='./lcqmc/LCQMC_train.csv' \
      --devset_path='./lcqmc/LCQMC_dev.csv' \
      --testset_path='./lcqmc/LCQMC_test.csv' \
      --train_batch_size=128 \
      --eval_batch_size=128 \
      --model_save_path
    ```
  
  - ä¸»è¦å‚æ•°è¯´æ˜
  
    - æ¨¡å‹é¢„æµ‹æ—¶åˆ™ä½¿ç”¨ `--do_eval`
    - æ•°æ®é›†ä¸º `sentence1, sentence2, label` å½¢å¼çš„ csv æ–‡ä»¶
    - 16G æ˜¾å­˜è®¾ç½® batch size ä¸º 128



- ä½¿ç”¨ [Transformers](https://huggingface.co/transformers/) è‡ªå®šä¹‰æ•°æ®é›†å’Œ `BertForSiameseNetwork` æ¨¡å‹å¹¶ä½¿ç”¨ Trainer è®­ç»ƒï¼Œé€‚åˆå¤š GPU å¤§è§„æ¨¡æ ·æœ¬è®­ç»ƒ

  ```bash
  CUDA_VISIBLE_DEVICES=0,1,2,3 python transformers_trainer.py \
  	--do_train=True \
  	--do_eval=True \
  	--do_predict=False \
  	--model_name_or_path='./model/bert-base-chinese' \
  	--trainset_path='./samples/merge.csv' \
  	--devset_path='./samples/test.csv' \
  	--testset_path='./samples/test.csv' \
  	--output_dir='./output/transformers-merge-bert'
  ```

  

- ä½¿ç”¨ [Transformers](https://huggingface.co/transformers/) çš„ `BertForSequenceClassification` è¿›è¡Œå¥å¯¹åˆ†ç±»å¯¹æ¯”å®éªŒ

  ```bash
  CUDA_VISIBLE_DEVICES=0 python bert_for_seq_classification.py \
  	--do_train=True \
  	--do_eval=True \
  	--do_predict=False \
    --trainset_path='./lcqmc/LCQMC_train.csv' \
    --devset_path='./lcqmc/LCQMC_dev.csv' \
    --testset_path='./lcqmc/LCQMC_test.csv' \
    --output_dir='./output/transformers-bert-for-seq-classify'
  ```



### æ¨¡å‹è’¸é¦

ä½¿ç”¨ [TextBrewer](https://github.com/airaria/TextBrewer)  ä»¥åŠå‰æ–‡è‡ªå®šä¹‰çš„ `SiameseNetwork` è¿›è¡Œæ¨¡å‹è’¸é¦

```bash
CUDA_VISIBLE_DEVICES=0 python model_distillation.py \
	--teacher_model='./output/transformers-merge-bert' \
	--student_config='./distills/bert_config_L3.json' \
	--bert_model='./model/bert-base-chinese' \
	--train_file='./samples/train.csv' \
	--test_file='./samples/test.csv' \
	--output_dir='./distills/outputs/bert-L3'
```

ä¸»è¦å‚æ•°è¯´æ˜ï¼š

- æ­¤å¤„ä½¿ç”¨çš„ `bert_config_L3.json` ä½œä¸ºå­¦ç”Ÿæ¨¡å‹å‚æ•°ï¼Œæ›´å¤šå‚æ•° [student_config](https://github.com/airaria/TextBrewer/tree/master/examples/student_config/bert_base_cased_config) æˆ–è€…è‡ªå®šä¹‰
- 3å±‚åº”ç”¨äºç‰¹å®šä»»åŠ¡æ•ˆæœä¸é”™ï¼Œä½†å¯¹äºå¥å‘é‡è·å–ï¼Œè‡³å°‘å¾—è’¸é¦ 6å±‚
- å­¦ç”Ÿæ¨¡å‹å¯ä»¥ä½¿ç”¨ `bert-base-chinese` çš„å‰å‡ å±‚åˆå§‹åŒ–



### WebæœåŠ¡

- æœåŠ¡å¯åŠ¨ï¼ˆ`gunicorn` å’Œ `uvicorn` å‡å¤šè¿›ç¨‹å¯åŠ¨ä»¥åŠæ”¯æŒå¤±è´¥é‡å¯ï¼‰
  - [Flask](https://flask.palletsprojects.com/)

    ```bash
    gunicorn -w 1 -b 127.0.0.1:8888 faq_app_flask:app
    ```
  
  - [FaskAPI](https://fastapi.tiangolo.com/) :fire: ï¼ˆæ¨èï¼‰ â€‹
  
    ```bash
    uvicorn faq_app_fastapi:app --reload --port=8888
    ```
  



- å‹åŠ›æµ‹è¯• [Locust](https://docs.locust.io/en/stable/) ï¼Œå®ç°è„šæœ¬å‚è€ƒ `locust_test.py`



## ç»“æœåŠåˆ†æ

### å¾®è°ƒç»“æœ

> å¯¹äºSiameseNetworkï¼Œéœ€è¦åœ¨å¼€å‘é›†ä¸Šç¡®å®šæœ€ä½³é˜ˆå€¼ï¼Œç„¶åæµ‹è¯•é›†ä¸Šä½¿ç”¨è¯¥é˜ˆå€¼è¿›è¡Œå¥å¯¹ç›¸ä¼¼åº¦ç»“æœè¯„ä»·

å¥å¯¹æµ‹è¯•é›†è¯„ä»·ç»“æœï¼Œæ­¤å¤„ä¸º LCQMC çš„å®éªŒç»“æœ

| model                                            | acc(dev/test) | f1(dev/test)  |
| ------------------------------------------------ | ------------- | ------------- |
| BertForSeqClassify<br />:steam_locomotive: lcqmc | 0.8832/0.8600 | 0.8848/0.8706 |
| SiameseNetwork<br />:steam_locomotive: lcqmc     | 0.8818/0.8705 | 0.8810/0.8701 |

> åŸºäºè¡¨ç¤ºå’ŒåŸºäºäº¤äº’çš„æ¨¡å‹æ•ˆæœå·®åˆ«å¹¶ä¸å¤§



### è¯­ä¹‰å¬å›ç»“æœ

> æ­¤å¤„ä¸º FAQ æ•°æ®é›†çš„å¬å›ç»“æœè¯„ä¼°ï¼Œå°†è®­ç»ƒé›† post ä½œä¸º corpusï¼Œæµ‹è¯•é›† post ä½œä¸º query è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—

| model                                                        | hit@1(chitchat-faq-small) | hit@1(entity-faq-large) |
| ------------------------------------------------------------ | ------------------------- | ----------------------- |
| *lucene bm25 (online)*                                       | 0.6679                    | -                       |
| bert-base-chinese                                            | 0.7394                    | 0.7745                  |
| bert-base-chinese<br />:point_up_2: *6 layers*               | 0.7276                    | -                       |
| SiameseNetwork<br />:steam_locomotive: chit-faq-small        | 0.8567                    | 0.8500                  |
| SiameseNetwork<br />:steam_locomotive: chitchat-faq-small + entity-faq-large | 0.8980                    | **0.9961**              |
| :point_up_2: *6 layers* :fire:                               | **0.9128**                | 0.8201                  |

- **chitchat-faq-small**
  - æµ‹è¯•é›† hit@1 å¤§çº¦ 85% å·¦å³
  - é”™è¯¯åŸå› ä¸»è¦æ˜¯ hflqa æ•°æ®é—®é¢˜
    - æ•°æ®è´¨é‡é—®é¢˜ï¼Œéƒ¨åˆ† topic æ„æ€ç›¸åŒï¼Œå¯ä»¥åˆå¹¶
    - ä¸€äº›ä¸å¸¸ç”¨è¡¨è¾¾æˆ–è€…è¡¨è¾¾ä¸å®Œæ•´çš„å¥å­
    - æ­£å¸¸å¯¹è¯çš„å¬å›ç‡è¿˜æ˜¯ä¸é”™çš„
- **chitchat-faq-small + entity-faq-large**
  - 2000 chitchat-faq-small æµ‹è¯•é›†ï¼Œ6å±‚æ¯”12å±‚æ•ˆæœå¥½ä¸€ä¸ªç‚¹ï¼Œhit@1 è¾¾åˆ° 90%
  - 10000 entity-faq-large æµ‹è¯•é›†ï¼Œ12å±‚ hit@1 è¾¾åˆ° 99%ï¼Œ6å±‚åªæœ‰ 82%
  - åº•å±‚å­¦åˆ°äº†è¾ƒä¸ºåŸºç¡€çš„ç‰¹å¾ï¼Œåœ¨åå‘é—²èŠçš„ chitchat-faq-small ä¸Šä»…ä½¿ç”¨6å±‚æ•ˆæœè¶…è¿‡12å±‚ï¼ˆæ²¡æœ‰è’¸é¦å¿…è¦ï¼‰
  - é«˜å±‚å­¦åˆ°äº†è¾ƒä¸ºé«˜çº§çš„ç‰¹å¾ï¼Œåœ¨åå‘å®ä½“çš„ entity-faq-large ä¸Š12å±‚æ•ˆæœè¿œè¶…äº6å±‚
  - å¦å¤–ï¼Œentity-faq-large æ•°é‡è§„æ¨¡è¿œå¤§äº chitchat-faq-small ï¼Œå› æ­¤æœ€åå‡ å±‚åˆ†ç±»å™¨åå‘äºä» entity-faq-large å­¦åˆ°çš„ä¿¡æ¯ï¼Œå› æ­¤åœ¨ chitchat-faq-small å°æ•ˆæœç•¥æœ‰ä¸‹é™ï¼›åŒæ—¶èƒ½å¤Ÿé¿å… chitchat-faq-small æ•°æ®è¿‡æ‹Ÿåˆ



### WebæœåŠ¡å‹æµ‹

- è¿è¡Œå‘½ä»¤è¯´æ˜

  > æ€»å…± 100 ä¸ªæ¨¡æ‹Ÿç”¨æˆ·ï¼Œå¯åŠ¨æ—¶æ¯ç§’é€’å¢ 10 ä¸ªï¼Œå‹åŠ›æµ‹è¯•æŒç»­ 3 åˆ†é’Ÿ

  ```bash
  locust  -f locust_test.py  --host=http://127.0.0.1:8889/module --headless -u 100 -r 10 -t 3m
  ```



- :hourglass: é…ç½® **4æ ¸8G CPU** ï¼ˆ6å±‚å°æ¨¡å‹å ç”¨å†…å­˜çº¦ 700MBï¼‰
  - å°æœåŠ¡å™¨ä¸Š **bert-as-service** æœåŠ¡éå¸¸ä¸ç¨³å®šï¼ˆtensorflowå„ç§æŠ¥é”™ï¼‰ï¼Œ æ•ˆç‡ä¸å¦‚ç®€å•å°è£…çš„ **TransformersEncoder** 
  - **FastAPI** æ¡†æ¶é€Ÿåº¦è¿œèƒœäº **Flask**ï¼Œçš„ç¡®å ªç§°æœ€å¿«çš„ Python Web æ¡†æ¶
  - **cache** çš„ä½¿ç”¨èƒ½å¤Ÿå¤§å¤§æé«˜å¹¶å‘é‡å’Œå“åº”é€Ÿåº¦ï¼ˆæœ€å¤§ç¼“å­˜å‡è®¾ç½®ä¸º**500**ï¼‰
  - æœ€ç»ˆæ¨èé…ç½® :fire: **TransformersEncoder + FastAPI  + functools.lru_cache**

| model                                                     | Web         | Cache         | User   | reqs    | fails | Avg   | Min  | Max     | Median | req/s      | fails/s |
| --------------------------------------------------------- | ----------- | ------------- | ------ | ------- | ----- | ----- | ---- | ------- | ------ | ---------- | ------- |
| *lucene bm25 (online)*                                    | *flask*     | *werkzeug*    | *1000* | *48969* | *0*   | *91*  | *3*  | *398*   | *79*   | **271.75** | 0.00    |
| BertSiameseNet<br/>â€‹â€‹6 layers <br/>Transformers             | flask       | flask-caching | 1000   | 4424    | 654(  | 28005 | 680  | 161199  | 11000  | 24.55      | 3.63    |
| BertSiameseNet<br/>6 layers <br />Transformers            | **fastapi** | lru_cache     | 1000   | 23566   | 1725  | 3884  | 6    | 127347  | 26     | **130.87** | 9.58    |
| *lucene bm25 (online)*                                    | *flask*     | *werkzeug*    | *100*  | *4973*  | *1*   | *32*  | *6*  | *60077* | *10*   | **27.66**  | 0.01    |
| BertSiameseNet<br/>6 layers <br/>bert-as-service          | flask       | flask-caching | 100    | 987     | 0     | 13730 | 357  | 17884   | 14000  | 5.49       | 0.00    |
| BertSiameseNet<br/>6 layers <br />Transformers            | flask       | flask-caching | 100    | 1066    | 0     | 12379 | 236  | 17062   | 12000  | 5.93       | 0.00    |
| BertSiameseNet<br/>:fire: 6 layers <br />**Transformers** | **fastapi** | **lru_cache** | 100    | 3993    | 0     | 824   | 10   | 2402    | 880    | **22.19**  | 0.00    |
| BertSiameseNet<br/>6 layers<br />transformers             | fastapi     | None          | 100    | 1900    | 0     | 1876  | 138  | 3469    | 1900   | 18.17      | 0.00    |

> ä½¿ç”¨ bert-as-service é‡åˆ°çš„ä¸€äº›é—®é¢˜ï¼š
>
> - è€ç‰ˆæœ¬æœåŠ¡å™¨ä¸Šä½¿ç”¨ [tensorflow æŠ¥é”™è§£å†³æ–¹æ¡ˆ Error in `python': double free or corruption (!prev) #6968](https://github.com/tensorflow/tensorflow/issues/6968#issuecomment-279060156)
>
> - æŠ¥é”™ src/tcmalloc.cc:277] Attempt to free invalid pointer 0x7f4685efcd40 Aborted (core dumpeï¼‰ï¼Œè§£å†³æ–¹æ¡ˆï¼Œå°† bert_as_service import ç§»åˆ°é¡¶éƒ¨



## æ›´å¤š

- å¤§è§„æ¨¡é—®é¢˜é›†å¯ä»¥ä½¿ç”¨ [facebookresearch/faiss](https://github.com/facebookresearch/faiss) ï¼ˆå»ºç«‹å‘é‡ç´¢å¼•ï¼Œä½¿ç”¨ k-nearest-neighbor å¬å›ï¼‰
- å¾ˆå¤šåœºæ™¯ä¸‹ï¼ŒåŸºäºå…³é”®å­—çš„å€’æ’ç´¢å¼•å¬å›ç»“æœå·²ç»è¶³å¤Ÿï¼Œå¯ä»¥è€ƒè™‘ç»¼åˆåŸºäºå…³é”®å­—å’ŒåŸºäºå‘é‡çš„å¬å›æ–¹æ³•ï¼Œå‚è€ƒçŸ¥ä¹è¯­ä¹‰æ£€ç´¢ç³»ç»Ÿ [Beyond Lexical: A Semantic Retrieval Framework for Textual SearchEngine](http://arxiv.org/abs/2008.03917)

